{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Data Wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "This lesson meets the following learning objectives:\n",
    "- The ability to use Python for data wrangling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Read through all of the text in this page. This assignment provides step-by-step training divided into numbered sections. The sections often contain embeded exectable code for demonstration.  Section headers with icons have special meanings:  \n",
    "\n",
    "- <i class=\"fas fa-puzzle-piece\"></i> The puzzle icon indicates that the section provides a practice exercise that must be completed.  Follow the instructions for the exercise and do what it asks.  Exercises must be turned in for credit.\n",
    "- <i class=\"fa fa-cogs\"></i> The cogs icon indicates that the section provides a task to perform.  Follow the instructions to complete the task.  Tasks are not turned in for credit but must be completed to continue progress.\n",
    "\n",
    "Review the list of items in the **Expected Outcomes** section to check that you feel comfortable with the material you just learned. If you do not, then take some time to re-review that material again. If after re-review you are not comfortable, do not feel confident or do not understand the material, please ask questions on Slack to help.\n",
    "\n",
    "Follow the instructions in the **What to turn in** section to turn in the exercises of the assginment for course credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The purpose of this assignment is to build on Tidy data cleaning by using Python tools to \"massage\" or \"wrangle\" data into formats that are most useful for visualization and analytics.\n",
    "\n",
    "**What is data wrangling?**\n",
    "\n",
    "> Data wrangling, sometimes referred to as data munging, is the process of transforming and mapping data from one \"raw\" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. \n",
    "\n",
    "- [Data Wangling](https://en.wikipedia.org/wiki/Data_wrangling) *Wikipedia*\n",
    "\n",
    "Previously, we learned about Tidy rules for reformatting data.  Transforming data into a Tidy dataset is data wrangling.  We have also learned to how to correct data types, remove missing values and duplicates.  This lessons is, therefore, an opportunity to bring everything together.  Some of the material will be a review, but should help reinforce the concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i class=\"fa fa-cogs\"></i> Notebook Setup\n",
    "As before, we import any needed packages at the top of our notebook. Let's import Numpy and Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "The first step in any data analytics task is import and exploration of data.  At this point, we have learned all of the steps we need to identify the data columns, their data types, recognize where we have missing values and recognize categorical and numeric variables in the data.   \n",
    "\n",
    "For this tutorial we will use a dataset named \"Abolone\" from the [University of California Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Abalone). The datafile is named `abalone.data` and is available in the data directory that accompanies this notebook.  The data has 10 \"attributes\" or variables. The following table describes these 10 variables, their types, and additional details.\n",
    "\n",
    "<table>\n",
    "    <tr><th>Name</th><th>Data Type</th><th>Metric</th><th>Description</th></tr>\n",
    "    <tr><td>Sample ID</td><td>integer</td><td></td><td>A unique number for each sample taken</td></tr>\n",
    "    <tr><td>Sex</td><td>nominal</td><td></td><td>M = 0, F = 1, and I = 2 (infant)</td></tr>\n",
    "\t<tr><td>Length</td><td>continuous</td><td>mm</td><td>Longest shell measurement</td></tr>\n",
    "\t<tr><td>Diameter</td><td>continuous</td><td>mm</td><td>perpendicular to length</td></tr>\n",
    "\t<tr><td>Height</td><td>continuous</td><td>mm</td><td>with meat in shell</td></tr>\n",
    "\t<tr><td>Whole weight</td><td>continuous</td><td>grams</td><td>whole abalone</td></tr>\n",
    "\t<tr><td>Shucked weight</td><td>continuous</td><td>grams</td><td>weight of meat</td></tr>\n",
    "\t<tr><td>Viscera weight</td><td>continuous</td><td>grams</td><td>gut weight (after bleeding)</td></tr>\n",
    "\t<tr><td>Shell weight</td><td>continuous</td><td>grams</td><td>after being dried</td></tr>\n",
    "\t<tr><td>Rings</td><td>integer</td><td></td><td>+1.5 gives the age in years</td></tr>\n",
    "</table>\n",
    "\n",
    "***Note:*** To demonstrate specific techniques of data wrangling, the dataset provided to you was altered: a sample ID column was added, the Sex column contains numeric IDs, and missing values were added as were duplicates.\n",
    "\n",
    "This data has no header information, so, we'll provide it when we import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>2</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0       1000    0   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       1001    0   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       1002    1   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       1003    0   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       1004    2   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera_weight  Shell_weight  Rings  \n",
       "0          0.1010         0.150     15  \n",
       "1          0.0485         0.070      7  \n",
       "2          0.1415         0.210      9  \n",
       "3          0.1140         0.155     10  \n",
       "4          0.0395         0.055      7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone = pd.read_csv('data/abalone.data', header = None)\n",
    "abalone.columns = ['Sample_ID','Sex', 'Length', 'Diameter', 'Height', \n",
    "          'Whole_weight', 'Shucked_weight', 'Viscera_weight', \n",
    "          'Shell_weight', 'Rings']\n",
    "abalone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Exploring Data Types\n",
    "First, let's explore how Pandas imported the data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample_ID           int64\n",
       "Sex                 int64\n",
       "Length            float64\n",
       "Diameter          float64\n",
       "Height            float64\n",
       "Whole_weight      float64\n",
       "Shucked_weight    float64\n",
       "Viscera_weight    float64\n",
       "Shell_weight      float64\n",
       "Rings               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the first, second and last columns, all others were imported as `float64` which is a decimal value. The others were imported as an `integer`.  This looks correct for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sense of how big the data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4186, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can explore the distribution of numerical data using the `describe` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4186.000000</td>\n",
       "      <td>4186.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4185.000000</td>\n",
       "      <td>4186.000000</td>\n",
       "      <td>4185.000000</td>\n",
       "      <td>4186.000000</td>\n",
       "      <td>4185.000000</td>\n",
       "      <td>4186.000000</td>\n",
       "      <td>4186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3086.700669</td>\n",
       "      <td>0.955805</td>\n",
       "      <td>0.523635</td>\n",
       "      <td>0.407621</td>\n",
       "      <td>0.139406</td>\n",
       "      <td>0.827486</td>\n",
       "      <td>0.358964</td>\n",
       "      <td>0.180390</td>\n",
       "      <td>0.238535</td>\n",
       "      <td>9.930244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1206.816977</td>\n",
       "      <td>0.828239</td>\n",
       "      <td>0.120323</td>\n",
       "      <td>0.099446</td>\n",
       "      <td>0.041890</td>\n",
       "      <td>0.490774</td>\n",
       "      <td>0.222266</td>\n",
       "      <td>0.109723</td>\n",
       "      <td>0.139352</td>\n",
       "      <td>3.222740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2039.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.185125</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3085.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4131.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.501500</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5178.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sample_ID          Sex       Length     Diameter       Height  \\\n",
       "count  4186.000000  4186.000000  4184.000000  4185.000000  4186.000000   \n",
       "mean   3086.700669     0.955805     0.523635     0.407621     0.139406   \n",
       "std    1206.816977     0.828239     0.120323     0.099446     0.041890   \n",
       "min    1000.000000     0.000000     0.075000     0.055000     0.000000   \n",
       "25%    2039.250000     0.000000     0.450000     0.350000     0.115000   \n",
       "50%    3085.500000     1.000000     0.545000     0.425000     0.140000   \n",
       "75%    4131.750000     2.000000     0.615000     0.480000     0.165000   \n",
       "max    5178.000000     2.000000     0.815000     0.650000     1.130000   \n",
       "\n",
       "       Whole_weight  Shucked_weight  Viscera_weight  Shell_weight        Rings  \n",
       "count   4185.000000     4186.000000     4185.000000   4186.000000  4186.000000  \n",
       "mean       0.827486        0.358964        0.180390      0.238535     9.930244  \n",
       "std        0.490774        0.222266        0.109723      0.139352     3.222740  \n",
       "min        0.002000        0.001000        0.000500      0.001500     1.000000  \n",
       "25%        0.440500        0.185125        0.092500      0.130000     8.000000  \n",
       "50%        0.798000        0.335500        0.170500      0.233000     9.000000  \n",
       "75%        1.153000        0.501500        0.252500      0.328500    11.000000  \n",
       "max        2.825500        1.488000        0.760000      1.005000    29.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that even though the 'Sex' column was provided as a numeric value, it is actually meant to be categorical, with each sex represented as a unique number.  We can explore the categorical data using the `groupby` function, followed by the `size` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "0    1532\n",
       "1    1307\n",
       "2    1347\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.groupby(by=['Sex']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Finding Missing Values\n",
    "Before proceeding with any analysis you should know the state of missing values in the dataset.  For most analytics missing values are not supported. Some tools will automatically ignore them but it may be easier, in some cases, to remove them.\n",
    "\n",
    "First, let's quantify how many missing values we have. The `isna` function will convert the data into `True` or `False` values: `True` if the value is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID    Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0      False  False   False     False   False         False           False   \n",
       "1      False  False   False     False   False         False           False   \n",
       "2      False  False   False     False   False         False           False   \n",
       "3      False  False   False     False   False         False           False   \n",
       "4      False  False   False     False   False         False           False   \n",
       "\n",
       "   Viscera_weight  Shell_weight  Rings  \n",
       "0           False         False  False  \n",
       "1           False         False  False  \n",
       "2           False         False  False  \n",
       "3           False         False  False  \n",
       "4           False         False  False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.isna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `sum` function to then identify how many missing values we have per column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample_ID         0\n",
       "Sex               0\n",
       "Length            2\n",
       "Diameter          1\n",
       "Height            0\n",
       "Whole_weight      1\n",
       "Shucked_weight    0\n",
       "Viscera_weight    1\n",
       "Shell_weight      0\n",
       "Rings             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Inspecting Duplicates\n",
    "Sometimes we may or may not want duplicates in the data. This depends on the expectations of the experiments and the measurements taken. Sometimes duplicates may represent human error in data entry. So, let's look for duplicated data.  We have 4,184 rows, let's see how many unique values per column that we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample_ID         4179\n",
       "Sex                  3\n",
       "Length             134\n",
       "Diameter           111\n",
       "Height              51\n",
       "Whole_weight      2429\n",
       "Shucked_weight    1515\n",
       "Viscera_weight     880\n",
       "Shell_weight       926\n",
       "Rings               28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all of the columns we have fewer that 4,184 values.  For columns like 'Sex' we have 3 unique values, but these repeated values are expected.  The decimal values also have duplicates. The likelihood of seeing the exact same decimal values varies based on the distribution for the variable and the number of decimal values in the measurement.  The number of duplicated values does not seem unordinary.  However, the sample ID should be unique, yet we have 4,177 of them instead of 4,184. This implies we have duplicated samples in the data. \n",
    "\n",
    "We can identify then umber of duplicated 'Sample_ID' values are in the data by using the `duplicated` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.duplicated(subset='Sample_ID').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 7 duplicated rows. Now let's see which rows have duplicated samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>1711</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>1712</td>\n",
       "      <td>2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>1714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>1715</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>1716</td>\n",
       "      <td>2</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>1717</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>1711</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>1712</td>\n",
       "      <td>2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>1714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>1715</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>1716</td>\n",
       "      <td>2</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4185</th>\n",
       "      <td>1717</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "711        1711    0   0.375     0.300   0.100        0.2465          0.1040   \n",
       "712        1712    2   0.280     0.205   0.055        0.1135          0.0450   \n",
       "713        1713    0   0.355     0.265   0.085        0.2010          0.0690   \n",
       "714        1714    0   0.350     0.255   0.080        0.1915          0.0800   \n",
       "715        1715    2   0.275     0.200   0.065        0.1035          0.0475   \n",
       "716        1716    2   0.290     0.205   0.070        0.0975          0.0360   \n",
       "717        1717    2   0.250     0.190   0.060        0.0765          0.0360   \n",
       "4179       1711    0   0.375     0.300   0.100        0.2465          0.1040   \n",
       "4180       1712    2   0.280     0.205   0.055        0.1135          0.0450   \n",
       "4181       1713    0   0.355     0.265   0.085        0.2010          0.0690   \n",
       "4182       1714    0   0.350     0.255   0.080        0.1915          0.0800   \n",
       "4183       1715    2   0.275     0.200   0.065        0.1035          0.0475   \n",
       "4184       1716    2   0.290     0.205   0.070        0.0975          0.0360   \n",
       "4185       1717    2   0.250     0.190   0.060        0.0765          0.0360   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "711           0.0475        0.0830     11  \n",
       "712           0.0275        0.0335      7  \n",
       "713           0.0530        0.0695      8  \n",
       "714           0.0385        0.0630      9  \n",
       "715           0.0205        0.0300      7  \n",
       "716           0.0190        0.0350      8  \n",
       "717           0.0115        0.0245      6  \n",
       "4179          0.0475        0.0830     11  \n",
       "4180          0.0275        0.0335      7  \n",
       "4181          0.0530        0.0695      8  \n",
       "4182          0.0385        0.0630      9  \n",
       "4183          0.0205        0.0300      7  \n",
       "4184          0.0190        0.0350      8  \n",
       "4185          0.0115        0.0245      6  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone[abalone.duplicated(subset='Sample_ID', keep= False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the rows are exact duplicates, so this was probably human entry error. We need to remove the copies rows. We will do so in the **3.1 Filtering** section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleanup\n",
    "### 2.1 Correcting Data Types\n",
    "During the data exploration phase above, we noticed that the Sex column was provided as a number to represent the Sex category, and therefore, Pandas imported that column as a numeric value. We need to convert that to a categorical value, because the meaning of the column is not ordinal or numeric. We should covert it to a string object.\n",
    "\n",
    "We can do that with two functions that work on Series:  \n",
    "- `astype`  converts the type of data in the series. \n",
    "- `replace`  replaces values in the series.\n",
    "\n",
    "We'll use `astype` to convert the column to a string and `replace` to convert the numbers to more easily recognizable 'Male', 'Female' and 'Infant' strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>Infant</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID     Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0       1000    Male   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       1001    Male   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       1002  Female   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       1003    Male   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       1004  Infant   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera_weight  Shell_weight  Rings  \n",
       "0          0.1010         0.150     15  \n",
       "1          0.0485         0.070      7  \n",
       "2          0.1415         0.210      9  \n",
       "3          0.1140         0.155     10  \n",
       "4          0.0395         0.055      7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First convert the column from an integer to a string.\n",
    "sex = abalone['Sex'].astype(str)\n",
    "\n",
    "# Second convert 0 to Male, 1 to Female, and 2 to Infant.\n",
    "sex = sex.replace('0', 'Male')\n",
    "sex = sex.replace('1', 'Female')\n",
    "sex = sex.replace('2', 'Infant')\n",
    "\n",
    "# Now replace the 'Sex' column of the dataframe with the new Series.\n",
    "abalone['Sex'] = sex\n",
    "abalone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the Sample ID column, despite that it is numeric should not be treated as a numeric column, so let's convert that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample_ID          object\n",
       "Sex                object\n",
       "Length            float64\n",
       "Diameter          float64\n",
       "Height            float64\n",
       "Whole_weight      float64\n",
       "Shucked_weight    float64\n",
       "Viscera_weight    float64\n",
       "Shell_weight      float64\n",
       "Rings               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Sample_ID to a string\n",
    "abalone['Sample_ID'] = abalone['Sample_ID'].astype(str)\n",
    "\n",
    "# Let's check out the datatypes to make sure they match our expectations:\n",
    "abalone.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Handling Missing Values\n",
    "As observed in section 2.2, we do indeed have missing values! Let's remove rows with missing values.  We can do so with the `dropna` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4184, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone = abalone.dropna(axis=0)\n",
    "abalone.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the `axis` argument is set to 0 indicating we will remove rows with missing values. If we compare the `shape` of the dataframe now, with the shape when we first loaded it we will see that we have lost 2 rows with missing values.\n",
    "\n",
    "In addition to `dropna` you can also use the `fillna` and `replace` functions to rewrite the missing values to something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove duplicates we can use the [drop_duplicates](http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.drop_duplicates.html) function of Pandas.  If we explore the duplicated columns of section 2.3 above we'll see that the rows are the same for all columns.  In this case we can call `drop_duplicates` with no arguments.  However, let's assume we can't guarantee that each column is the same,  but we do want to remove duplicated samples.  We can do this by using the `subset` argument of the `drop_duplicates` function. We don't want to drop all duplicates, we need to keep one set. Therefore, we'll use the `keep` argument to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone = abalone.drop_duplicates(['Sample_ID'], keep='first')\n",
    "abalone.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the `keep` argument will default to `first` so we don't need to provide it, but including it makes the code more clear.  We have now dropped all duplicated rows and we have 4,177 valid rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reshaping Data\n",
    "Data reshaping is about altering the way data is housed in the data frames of Pandas. It includes filtering of rows, merging data frames, concatenating data frames, grouping, melting and pivoting. We have learned about all of these functions already. As a reminder, the following is a summary of what we've learned:\n",
    "\n",
    "**Subsetting by Column**:\n",
    "- *Indexing with column names*\n",
    "  - Purpose: Allows you to slice the dataframe using column index names.\n",
    "  - Introduced:  Pandas Part 1 Notebook\n",
    "  - Example:\n",
    "  ```python\n",
    "   # Get the columns: Sample_ID, Sex, Height and Rings\n",
    "   subset = abalone[['Sample_ID', 'Sex', 'Height', 'Rings']]\n",
    "  ```\n",
    "- *Indexing with the `loc` function*\n",
    "  - Purpose: Allows you to slice the dataframe using row and column index names.\n",
    "  - Introduced:  Pandas Part 1 Notebook\n",
    "  - Example:\n",
    "  ```python\n",
    "   # Get the columns: Sample_ID, Sex, Height and Rings\n",
    "   subset = abalone.loc[:,['Sample_ID', 'Sex', 'Height', 'Rings']]\n",
    "  ```    \n",
    "  \n",
    "**Filtering Rows**:\n",
    "- *Boolean Indexing*\n",
    "  - Purpose: to filter rows that match desired criteria\n",
    "  - Introduced:  Pandas Part 1 Notebook\n",
    "  - Example: \n",
    "  \n",
    "  ```python\n",
    "   # Finds all rows with sex of \"Male\" and the number of rings > 3.\n",
    "   matches = (abalone['Sex'] == 'Male') & (abalone['Rings'] > 3)\n",
    "   male = abalone[matches]\n",
    "\n",
    "   # Or more succinctly\n",
    "   male = abalone[(abalone['Sex'] == 'Male') & (abalone['Rings'] > 3)]\n",
    "  ```\n",
    "\n",
    "**Grouping Data**:\n",
    "- *`groupby` function*\n",
    "  - Purpose:  To group rows together by \"classes\" or values of data. Allows you to perform aggregate functions, such as calculating means, summations, sizes, etc. You can create new data frames with aggregated values.\n",
    "  - Introduced:  Pandas Part 2 Notebook. \n",
    "  - Example:\n",
    "  ```python\n",
    "  # Calculate the mean column value by each sex:\n",
    "  abalone.groupby(by=\"Sex\").mean()\n",
    "  ```\n",
    "  \n",
    "**Merging DataFrames**:\n",
    "- *`concat` function*\n",
    "  - Purpose: To combine two dataframes.  Depending if the columns and row indexes are the same determines how the data frames are combined.\n",
    "  - Introduced:  Pandas Part 2 Notebook.\n",
    "\n",
    "**Melting**:\n",
    "- *`melt` function*\n",
    "  - Purpose:  Handles the case where categorical observations are stored in the header labels (i.e. violates Tidy rules).  It moves the header names into a new column and matches the corresponding values.\n",
    "  - Introduced:  Tidy Part 1 Notebook.\n",
    "\n",
    "**Pivoting**:\n",
    "- *`pivot` and `pivot_table` functions*\n",
    "  - Purpose: The opposite of `melt`. Uses unique values from one more columns to create new columns.\n",
    "  - Intorduced: Tidy Part 1 Notebook.\n",
    "  \n",
    "You can use any of these functions/techniques to reshape the data to meet Tidy standards and appropriate for the analytic or visualization you want to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <i class=\"fas fa-puzzle-piece\"></i> Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the apple data found in the `../data/apple_data.txt` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>1982</th>\n",
       "      <th>1987</th>\n",
       "      <th>1992</th>\n",
       "      <th>1997</th>\n",
       "      <th>2002</th>\n",
       "      <th>2007</th>\n",
       "      <th>1982</th>\n",
       "      <th>1987</th>\n",
       "      <th>1992.1</th>\n",
       "      <th>1997.1</th>\n",
       "      <th>2002.1</th>\n",
       "      <th>2007.1</th>\n",
       "      <th>2002.2</th>\n",
       "      <th>2007.2</th>\n",
       "      <th>2002.3</th>\n",
       "      <th>2007.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>899</td>\n",
       "      <td>626</td>\n",
       "      <td>474</td>\n",
       "      <td>479</td>\n",
       "      <td>265</td>\n",
       "      <td>231</td>\n",
       "      <td>1,548</td>\n",
       "      <td>1,217</td>\n",
       "      <td>1,011</td>\n",
       "      <td>968</td>\n",
       "      <td>594</td>\n",
       "      <td>393</td>\n",
       "      <td>191</td>\n",
       "      <td>144</td>\n",
       "      <td>386</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>(D)</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>(D)</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>214</td>\n",
       "      <td>224</td>\n",
       "      <td>235</td>\n",
       "      <td>158</td>\n",
       "      <td>185</td>\n",
       "      <td>496</td>\n",
       "      <td>1,969</td>\n",
       "      <td>4,881</td>\n",
       "      <td>5,770</td>\n",
       "      <td>4,003</td>\n",
       "      <td>1,581</td>\n",
       "      <td>1,344</td>\n",
       "      <td>118</td>\n",
       "      <td>424</td>\n",
       "      <td>1,459</td>\n",
       "      <td>1,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>512</td>\n",
       "      <td>451</td>\n",
       "      <td>247</td>\n",
       "      <td>238</td>\n",
       "      <td>164</td>\n",
       "      <td>153</td>\n",
       "      <td>2,276</td>\n",
       "      <td>2,120</td>\n",
       "      <td>1,430</td>\n",
       "      <td>1,048</td>\n",
       "      <td>658</td>\n",
       "      <td>287</td>\n",
       "      <td>123</td>\n",
       "      <td>116</td>\n",
       "      <td>560</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2,904</td>\n",
       "      <td>2,787</td>\n",
       "      <td>3,082</td>\n",
       "      <td>3,454</td>\n",
       "      <td>2,120</td>\n",
       "      <td>2,074</td>\n",
       "      <td>29,933</td>\n",
       "      <td>34,105</td>\n",
       "      <td>42,024</td>\n",
       "      <td>49,704</td>\n",
       "      <td>38,268</td>\n",
       "      <td>22,184</td>\n",
       "      <td>1,850</td>\n",
       "      <td>1,850</td>\n",
       "      <td>35,856</td>\n",
       "      <td>20,954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           State    1982    1987    1992    1997    2002    2007     1982  \\\n",
       "0        Alabama    899     626     474     479     265     231    1,548    \n",
       "1         Alaska      --      --      2       4       9      10        --   \n",
       "2        Arizona    214     224     235     158     185     496    1,969    \n",
       "3       Arkansas    512     451     247     238     164     153    2,276    \n",
       "4     California  2,904   2,787   3,082   3,454   2,120   2,074   29,933    \n",
       "\n",
       "      1987   1992.1   1997.1   2002.1   2007.1 2002.2 2007.2  2002.3  2007.3  \n",
       "0   1,217    1,011      968      594      393     191    144     386     307  \n",
       "1       --      (D)       2       13       15       8     10     (D)     (D)  \n",
       "2   4,881    5,770    4,003    1,581    1,344     118    424   1,459   1,249  \n",
       "3   2,120    1,430    1,048      658      287     123    116     560     220  \n",
       "4  34,105   42,024   49,704   38,268   22,184   1,850  1,850  35,856  20,954  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table('data/apple_data.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data using the approach we've used thus far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       State    0\n",
       "1982            0\n",
       "1987            0\n",
       "1992            0\n",
       "1997            0\n",
       "2002            0\n",
       "2007            0\n",
       "  1982          0\n",
       "  1987          0\n",
       "1992.1          0\n",
       "1997.1          0\n",
       "2002.1          0\n",
       "2007.1          0\n",
       "2002.2          0\n",
       "2007.2          0\n",
       "2002.3          0\n",
       "2007.3          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       State    50\n",
       "1982            49\n",
       "1987            48\n",
       "1992            49\n",
       "1997            49\n",
       "2002            50\n",
       "2007            49\n",
       "  1982          49\n",
       "  1987          49\n",
       "1992.1          49\n",
       "1997.1          48\n",
       "2002.1          48\n",
       "2007.1          48\n",
       "2002.2          46\n",
       "2007.2          49\n",
       "2002.3          46\n",
       "2007.3          48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       State    object\n",
       "1982            object\n",
       "1987            object\n",
       "1992            object\n",
       "1997            object\n",
       "2002            object\n",
       "2007            object\n",
       "  1982          object\n",
       "  1987          object\n",
       "1992.1          object\n",
       "1997.1          object\n",
       "2002.1          object\n",
       "2007.1          object\n",
       "2002.2          object\n",
       "2007.2          object\n",
       "2002.3          object\n",
       "2007.3          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>1982</th>\n",
       "      <th>1987</th>\n",
       "      <th>1992</th>\n",
       "      <th>1997</th>\n",
       "      <th>2002</th>\n",
       "      <th>2007</th>\n",
       "      <th>1982</th>\n",
       "      <th>1987</th>\n",
       "      <th>1992.1</th>\n",
       "      <th>1997.1</th>\n",
       "      <th>2002.1</th>\n",
       "      <th>2007.1</th>\n",
       "      <th>2002.2</th>\n",
       "      <th>2007.2</th>\n",
       "      <th>2002.3</th>\n",
       "      <th>2007.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>392</td>\n",
       "      <td>485</td>\n",
       "      <td>265</td>\n",
       "      <td>35</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>(D)</td>\n",
       "      <td>5,389</td>\n",
       "      <td>(D)</td>\n",
       "      <td>(D)</td>\n",
       "      <td>8</td>\n",
       "      <td>427</td>\n",
       "      <td>(D)</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              State 1982 1987  1992  1997  2002 2007   1982   1987 1992.1  \\\n",
       "count            50   50   50    50    50    50   50     50     50     50   \n",
       "unique           50   49   48    49    49    50   49     49     49     49   \n",
       "top         Alabama   --   --  392   485   265   35      --     --    (D)   \n",
       "freq              1    2    2     2     2     1    2      2      2      2   \n",
       "\n",
       "        1997.1 2002.1 2007.1 2002.2 2007.2 2002.3 2007.3  \n",
       "count       50     50     50     50     50     50     50  \n",
       "unique      48     48     48     46     49     46     48  \n",
       "top     5,389     (D)    (D)      8    427    (D)    (D)  \n",
       "freq         2      3      3      2      2      5      3  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "21    False\n",
       "22    False\n",
       "23    False\n",
       "24    False\n",
       "25    False\n",
       "26    False\n",
       "27    False\n",
       "28    False\n",
       "29    False\n",
       "30    False\n",
       "31    False\n",
       "32    False\n",
       "33    False\n",
       "34    False\n",
       "35    False\n",
       "36    False\n",
       "37    False\n",
       "38    False\n",
       "39    False\n",
       "40    False\n",
       "41    False\n",
       "42    False\n",
       "43    False\n",
       "44    False\n",
       "45    False\n",
       "46    False\n",
       "47    False\n",
       "48    False\n",
       "49    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>1982</th>\n",
       "      <th>1987</th>\n",
       "      <th>1992</th>\n",
       "      <th>1997</th>\n",
       "      <th>2002</th>\n",
       "      <th>2007</th>\n",
       "      <th>1982</th>\n",
       "      <th>1987</th>\n",
       "      <th>1992.1</th>\n",
       "      <th>1997.1</th>\n",
       "      <th>2002.1</th>\n",
       "      <th>2007.1</th>\n",
       "      <th>2002.2</th>\n",
       "      <th>2007.2</th>\n",
       "      <th>2002.3</th>\n",
       "      <th>2007.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>899</td>\n",
       "      <td>626</td>\n",
       "      <td>474</td>\n",
       "      <td>479</td>\n",
       "      <td>265</td>\n",
       "      <td>231</td>\n",
       "      <td>1,548</td>\n",
       "      <td>1,217</td>\n",
       "      <td>1,011</td>\n",
       "      <td>968</td>\n",
       "      <td>594</td>\n",
       "      <td>393</td>\n",
       "      <td>191</td>\n",
       "      <td>144</td>\n",
       "      <td>386</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>(D)</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>(D)</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>214</td>\n",
       "      <td>224</td>\n",
       "      <td>235</td>\n",
       "      <td>158</td>\n",
       "      <td>185</td>\n",
       "      <td>496</td>\n",
       "      <td>1,969</td>\n",
       "      <td>4,881</td>\n",
       "      <td>5,770</td>\n",
       "      <td>4,003</td>\n",
       "      <td>1,581</td>\n",
       "      <td>1,344</td>\n",
       "      <td>118</td>\n",
       "      <td>424</td>\n",
       "      <td>1,459</td>\n",
       "      <td>1,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>512</td>\n",
       "      <td>451</td>\n",
       "      <td>247</td>\n",
       "      <td>238</td>\n",
       "      <td>164</td>\n",
       "      <td>153</td>\n",
       "      <td>2,276</td>\n",
       "      <td>2,120</td>\n",
       "      <td>1,430</td>\n",
       "      <td>1,048</td>\n",
       "      <td>658</td>\n",
       "      <td>287</td>\n",
       "      <td>123</td>\n",
       "      <td>116</td>\n",
       "      <td>560</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2,904</td>\n",
       "      <td>2,787</td>\n",
       "      <td>3,082</td>\n",
       "      <td>3,454</td>\n",
       "      <td>2,120</td>\n",
       "      <td>2,074</td>\n",
       "      <td>29,933</td>\n",
       "      <td>34,105</td>\n",
       "      <td>42,024</td>\n",
       "      <td>49,704</td>\n",
       "      <td>38,268</td>\n",
       "      <td>22,184</td>\n",
       "      <td>1,850</td>\n",
       "      <td>1,850</td>\n",
       "      <td>35,856</td>\n",
       "      <td>20,954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           State    1982    1987    1992    1997    2002    2007     1982  \\\n",
       "0        Alabama    899     626     474     479     265     231    1,548    \n",
       "1         Alaska      --      --      2       4       9      10        --   \n",
       "2        Arizona    214     224     235     158     185     496    1,969    \n",
       "3       Arkansas    512     451     247     238     164     153    2,276    \n",
       "4     California  2,904   2,787   3,082   3,454   2,120   2,074   29,933    \n",
       "\n",
       "      1987   1992.1   1997.1   2002.1   2007.1 2002.2 2007.2  2002.3  2007.3  \n",
       "0   1,217    1,011      968      594      393     191    144     386     307  \n",
       "1       --      (D)       2       13       15       8     10     (D)     (D)  \n",
       "2   4,881    5,770    4,003    1,581    1,344     118    424   1,459   1,249  \n",
       "3   2,120    1,430    1,048      658      287     123    116     560     220  \n",
       "4  34,105   42,024   49,704   38,268   22,184   1,850  1,850  35,856  20,954  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['       State', '1982', '1987', '1992', '1997', '2002', '2007',\n",
       "       '  1982', '  1987', '1992.1', '1997.1', '2002.1', '2007.1', '2002.2',\n",
       "       '2007.2', '2002.3', '2007.3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidy the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Apples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1982</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1982</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>1982</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1982</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>1982</td>\n",
       "      <td>2,904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>1982</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1982</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>1982</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>1982</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>1982</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Year  Apples\n",
       "0         Alabama  1982    899 \n",
       "1          Alaska  1982      --\n",
       "2         Arizona  1982    214 \n",
       "3        Arkansas  1982    512 \n",
       "4      California  1982  2,904 \n",
       "5        Colorado  1982    608 \n",
       "6     Connecticut  1982    309 \n",
       "7        Delaware  1982     24 \n",
       "8         Florida  1982    196 \n",
       "9         Georgia  1982    893 "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_data = pd.melt(data, id_vars=['       State'],\n",
    "        var_name='Year', value_name='Apples')\n",
    "melted_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Outcomes\n",
    "At this point, you should feel comfortable with the following:\n",
    "- How to begin exploration of any dataset prior to analysis\n",
    "- Cleaning data and wrangling it into Tidy format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to Turn in?\n",
    "Be sure to **commit** and **push** your changes to this notebook.  All practice exercises should be completed.  Once completed, send a **Slack message** to the instructor indicating you have completed this assignment. The instructor will verify all work is completed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
